\subsection{Test of image identification} \label{sec:tests.t1}

A first manual evaluation tested the volunteers ability to reconstruct the arrival time surface given a survey image containing a sim.
This task consists of two parts.
First to correctly identify and locate the lensed images.
Second the correct ordering for the identified lensed images in respect of the arrival time.

While we expected the identification of lensed images to be trivial, given the nature of the survey images and the success of \sw, we expect the correct ordering to be more difficult.
This part tests the volunteers understandings of the theory of arrival time surfaces and the odd number theorem.
While we can provide the volunteers with some general rules of thumb, ordering involves imagination and guessing and therefore training could improve results in a later stage.

This first test was designed to give some feedback on the difficulties volunteers encounter, to further improve the tutorial materials.

The evaluation of the volunteers performance was done manually, comparing their input from \spl and the resulting reconstructed arrival time surface contour line plot (arrival plot) to the arrival plot generated using simulation parameters.
% \Figref{output_compare} shows the setup used to evaluate the models.

The images of the system are considered to be identified correctly, if all the images have been identified and are approximated within $\pm0.05\cdot\text{imgage width}$.
The parity is considered correct, if those identified points have the right ordering with respect to arrival time.

Additionally, ten types of errors (labeled E01 -- E10, listed in \tabref{stats}) that occurred were identified.
Each generated model could contain more than one error.

\begin{table}\centering\begin{tabular}{llcc}\hline
 & & n & p \\
\hline
 N: & Total number of models & 119 & 1.00\\
\hline
 R1: & images approx. on right location & 110 & 0.92\\
 R2: & images with correct parity & 70 & 0.59\\
\hline
 E01: & inaccurate in arc & 21 & 0.18\\
 E02: & wrong parity in 3 lens conf. & 2 & 0.02\\
 E03: & identified 3 of 5 imgs. & 5 & 0.04\\
 E04: & modeled arc with single img. & 4 & 0.03\\
 E05: & $\pi$ rotated parity & 7 & 0.06\\
 E06: & $\pi$/2 rotated parity & 38 & 0.32\\
 E07: & missed faint img. & 1 & 0.01\\
 E08: & too many imgs in arc. & 5 & 0.04\\
 E09: & missed double img & 3 & 0.03\\
 E10: & too many imgs. & 1 & 0.01\\
\end{tabular}

\caption{1. col: id of model; 2.col: places of imgs idendited
  correctly; 3. col: more or less correct identification of extr
  points. 4.col: exact identification of extremal points. 5.col:
  type(s) of errors ocured....  1) inaccurate placement in an extended
  arc; 2) wrongly identified sad and min in 3 image configuration; 3)
  identified only 3 instead of 5 images; 4) tried to model an arc with
  a min instead of min-sad-min; 5) PI-err (rotation by 180 degrees; in
  5 image configuration, exchanged the ordering of the two saddle
  points); 6) PI/2-err (rotation by 90 degree; sad-min-sad-min-sad);
  7) missed faint image(s); 8) tried to model an arc with min-sad-min
  instead of only min; 9) did identify two close by images as one; 10)
  used 7 or more image to model a 5 image system. }

\label{tab:stats}
\end{table}


\tabref{stats} presents a summary of this evaluation.
We conclude that the volunteers are performing very well identifying and positioning images, with a performance of 92\% (R1, p=0.92).
Most of the problems where due to unclear arc-like structures (E01, p=0.18; E04, p=0.03; E08, p=0.04).
Critical errors like the failure to identify all five images in a five images system (E03, p=0.04) or to include too many images (E10, p=0.01) did almost never happen.
From this we conclude that the introduction materials was adequate and the volunteers understand the basics of gravitational lensing.

The assignment of the parity of the images was a more difficult task.
In 59\% (R2, p=0.59, N=70) of the cases the volunteers succeeded to identify the right configuration.
Most of the failures are due to E06 (N=38, p=32\%), followed by E05 (N=7, p=6\%).
E06 describes a situation, where the minima and saddle points of a five image configuration were exchanged (rotated by $\pm90\dgr$), see \figref{7022} for an example.
E05 describes a situation, where the ordering of the saddle points was wrong (rotation by $180\dgr$).
While these errors occurred, we suspect they can be avoided with better training material and some examples for the obvious cases.
For more challenging cases, like very symmetrical distribution of the lensed images (for example model 7022, \figref{7022}), those errors should still produce plausible results, as will be explained in the next section.



\subsection{Test of mass-profile recovery} \label{sec:tests.t2}

The second test was to compare the mass distributions of the lens $\kappa(x, y)$ given by the sims and generated by the volunteers.
To get a means of comparing the sims to the models, the total convergence\footnote{often called enclosed mass} $\kappa_{\text{encl}}(r)$ was calculated for both.
The Einstein radius $\Theta_\text{E}$ is defined by $\kappa_{\text{encl}}(\Theta_\text{E})=1$ and gives a number that allows a rough comparison between a sim and a model.
We also let an expert (PS) model three selected systems to compare the results from volunteers to those of a professional.


To compare the enclosed mass profile and the Einstein radius of the simulation and the models, \kenc was calculated using the mass map \kap[x,y] generated in the modeling process.
From the ensemble of models generated by one modeling process, the mean is taken as the resulting $\kappa(r)$ to calculate \ERg.
To estimate the errors, the extremal models are used to estimate a lower and upper limit for \ERg.
These results can be seen in \figref{ER_per_sim}.
This figure shows that this technique of estimating the error using the ensemble of all models underestimates the error significantly and should be improved for further analysis.

\begin{figure*}
  \centering
    \includegraphics[width=0.90\linewidth]{fig/eR_5}
  \caption{Relative \ERf / \ERg[, sim] for models by volunteers (blue cross), models made by an expert (red cross with offset), including rejected models (green squares); binned per sim.}
  \label{fig:ER_per_sim}
\end{figure*}

\begin{figure}
  \centering
  \subfigure{\includegraphics[width=0.9\linewidth]
             {fig/007022_kappa_encl}}
  \subfigure{\includegraphics[width=0.9\linewidth]
             {fig/007025_kappa_encl}}
  \subfigure{\includegraphics[width=0.9\linewidth]
             {fig/007021_kappa_encl}} \\
  \caption{
  %Enclosed mass \kenc from three models of a system with incorrect image identifications. \figref{7022} shows a model (by an expert) with the correct identifications, while \figref{7025} shows a model with error E06 (parities rotated by $\pi/2$).  Shown here are the \kenc results for two models with error E06 and one model (bottom) with error E05 (parities rotated by $\pi$).
  }
\label{fig:kapenc_compare_faulty}
\end{figure}

\Figref{ER_per_sim} shows that the calculated \ERf of the models tend
to be too high.  The overshoot varies from around 0.2 to 0.4 for good
models.  Discounting the models which were flagged by the users as
poor, \ERf{E,rec} is overestimated.  The mean and standard deviation
of the overestimate are 25\% and 20\%.  The models by an expert also
show a similar bias, having mean and standard deviation of the
overestimate being 20\% and 8\%.
One of the reasons for this is that it is hard to get the center of the lens on spot.
An offset leads to a flatter mass profile for the model compared to the simulation.

Comparing the models from volunteers and experts can be done in Figures \ref{fig:7022}, \ref{fig:7025} and \ref{fig:kapenc_compare_faulty}, where only the
expert got the right configuration (\figref{7022}) but enclosed masses are all fairly similar.  In cases with nearly symmetric image configurations, like this example, it is more difficult to identify the image parities correctly.  Incorrect image-parity identification changes the orientation of the mass distribution \kap[x,y],
but \kenc and thus the \ERf are not influenced that much.

Two additional sims were modeled by an expert, \asw{1hpf} and \asw{0vqg}.
Looking at the results for \ERg for those models in \figref{ER_per_sim}, we conclude that the performance of volunteers (blue crosses) and experts (red crosses, offset) is comparable.
%Note that the models of \asw{0vqg} with \ERg[, rel] around 0.25 (6935 -- 6937) are failed models that show the attempts of a single user, that came finally up with model 6938 as final result.\todo{remove?}

\clearpage
\section{Outlook} \label{sec:todo}

The lens-modeling challenge indicates that the Spacewarps collective
is good, not only for identifying lens candidates for follow-up, but
modeling candidates as well.

There is, however, plenty of room for improvement.

First, the particular modeling strategy implemented is not the only
one possible.  \spl requires modelers to characterize the overall
image structure in abstract terms based on Fermat's principle, and the
placement of mass distributions is done by the computer.  In other
modeling tools, the user puts down a trial mass distribution and has
the machine refine it.  A few of these modeling programs have also
been designed with citizen science in mind, and would be interesting
in the Spacewarps environment.

Second, \spl needs some enhancements.

\begin{itemize}
\item Currently, \spl does not attempt to model the source shape; the
  user identifies the brightest points on the image, and these are
  taken as images of a point-like source, whose positions must be
  reproduced exactly. For generating a synthetic image, a conical
  source profile is assumed. Fitting for the source profile to
  optimize resemblance to the observed lensed image after the lens
  model has been generated, is algorithmically straightforward and
  planned to be implemented.  This would alleviate another problem
  with \spl, which is that there is no numerical figure of merit, and
  assessment of a model is a judgment call based on the synthetic
  image, and on whether the mass distribution and the arrival-time
  surface show suspect features.
\item \spl has a tendency to somewhat overestimate the Einstein radius
  (evident from Figure \ref{fig:ER_per_sim}), and it is also apparent
  that the models tend to be too shallow.  This possible explanation
  is that, while the sims are steeply peaked at the centre, the
  pixellated mass model fixes a comparatively large area near the
  central at constant density.  One way to solve this problem would be
  to introduce smaller pixels in the central region, thus enabled a
  steeper centre.
\item Another limitation so far in \spl is that the lens is assumed to
  be dominated by one galaxy, which puts most galaxy-group lenses
  beyond the reach of the modeler. Since complicated group lenses are
  some of the most interesting candidates present, removing this
  limitation is most desirable.  From the users' point of view, it
  would mean that spaghetti contours with more than one maximum can be
  allowed.  For examples, see Figure 5c in \citep{2001ApJ...557..594R}
  and Figure 4b in \cite{2003ApJ...590...39K}.
\item At present, a single false-color composite is used as the data.
  An option could be added to use all available filters, individually
  or in combination, at the user wishes.
\end{itemize}

The third desirable avenue of improvement is to facilitate
collaborative work.

\begin{itemize}
\item As mentioned above, the option of revising an already-archived
  model is already available.  Desired now are tools for comparing
  different models of a given system, both visually and through
  different statistical measures.  As evidenced by a current
  collaborative modeling effort, a particularly interesting candidate
  can lead to an extended discussion and dozens of models.
\item Better tutorial materials are also needed, and this would
  address some of the problem areas found in the modeling challenge.
  For example, we saw in \secref{tests.t1} that volunteers are most
  prone to making errors in two situations: when in identifying an arc-
  like structure while placing the points, and in identifying the
  correct ordering of the points in nearly-symmetric configurations.
\end{itemize}

\section{Acknowledgments}

We thank the Swiss Society for Astrophysics and Astronomy and the
Swiss Academy of Sciences.

\clearpage

